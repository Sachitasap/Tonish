#!/bin/bash

# Tonish AI Setup Script
# This script configures Tonish to use existing Ollama at 192.168.5.10:11434

set -e

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘        Tonish AI Integration Setup                     â•‘"
echo "â•‘        Using Existing Ollama Instance                  â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Check if Ollama is accessible
echo "ğŸ” Checking Ollama connection at 192.168.5.10:11434..."
if curl -s http://192.168.5.10:11434/api/tags > /dev/null 2>&1; then
    echo "âœ“ Ollama is accessible!"
else
    echo "âŒ Error: Cannot connect to Ollama at 192.168.5.10:11434"
    echo "Please ensure Ollama is running"
    exit 1
fi

echo ""
echo "ğŸ“‹ Listing available models..."
MODELS=$(curl -s http://192.168.5.10:11434/api/tags | grep -o '"name":"[^"]*"' | cut -d'"' -f4)

if echo "$MODELS" | grep -q "qwen2.5-coder"; then
    INSTALLED_MODEL=$(echo "$MODELS" | grep "qwen2.5-coder" | head -1)
    echo "âœ“ qwen2.5-coder model is already installed: $INSTALLED_MODEL"
    echo "  Using this model for Tonish AI"
else
    echo "âš ï¸  qwen2.5-coder model not found"
    echo "ğŸ“¥ Would you like to pull qwen2.5-coder:3b now? (y/n)"
    read -r RESPONSE
    if [[ "$RESPONSE" =~ ^[Yy]$ ]]; then
        echo "Pulling qwen2.5-coder:3b (this may take a few minutes)..."
        curl -X POST http://192.168.5.10:11434/api/pull \
            -d '{"name": "qwen2.5-coder:3b"}' \
            -H "Content-Type: application/json"
        echo ""
        echo "âœ“ Model pulled successfully!"
    fi
fi

echo ""
echo "ğŸ§ª Testing AI service..."

# Test the model
TEST_RESPONSE=$(curl -s http://192.168.5.10:11434/api/generate \
    -d '{
        "model": "qwen2.5-coder:3b",
        "prompt": "Reply with just the word ready",
        "stream": false
    }' | grep -o '"response":"[^"]*"' | head -1 | cut -d'"' -f4)

if [ -n "$TEST_RESPONSE" ]; then
    echo "âœ“ AI model is responding!"
    echo "  Response preview: ${TEST_RESPONSE:0:50}..."
else
    echo "âš ï¸  Warning: AI model may not be fully ready"
fi

echo ""
echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘              Setup Complete! ğŸ‰                        â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ¤– Ollama: http://192.168.5.10:11434"
echo "ğŸ“– Model: qwen2.5-coder:3b"
echo ""
echo "Configuration:"
echo "  OLLAMA_URL=http://192.168.5.10:11434"
echo "  OLLAMA_MODEL=qwen2.5-coder:3b"
echo ""
echo "Next steps:"
echo "  1. Start the full stack:"
echo "     $ docker-compose up -d"
echo ""
echo "  2. OR start development mode:"
echo "     $ ./start-dev.sh"
echo ""
echo "  3. Test AI health:"
echo "     $ curl http://192.168.5.10:8080/api/ai/health"
echo ""
echo "ğŸ“š Read AI_INTEGRATION_GUIDE.md for detailed documentation"
echo ""
